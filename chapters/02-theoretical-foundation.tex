\cleardoublepage
\chapter*{Theoretical Foundation}\label{ch:theoretical}
\addcontentsline{toc}{chapter}{Theoretical Foundation}
This chapter succinctly describes principles which build the foundation for later chapters.
Only the most relevant topics are touched upon, necessary details are explained in later chapters.
The mathematics that makes the techniques possible is not explained in depths as it would otherwise
exceed the scope of this work.
Whenever possible heavy mathematical notation is omitted if it does not aid the understanding of the
reader.

\section{Machine Learning}
To grasp \ac{DL}, a solid understanding of \ac{ML} has to be developed
first~\citep{goodfellow_deep_2016}.
This is because \ac{DL} is a subfield of \ac{ML}~\citep{chauhan_review_2018}.
The most well known definition for \ac{ML} comes from~\cite{mitchell_machine_1997}:
`A computer program is said to learn from experience $E$ with respect to some class of tasks $T$
and performance measure $P$, improves with experience $E$'.

% XXX: explain difference: model - algorithm
The task that the \ac{MLS} learns to perform, can range from approximating a function
(e.g.\ regression --- $f:\R^n \rightarrow \R^l$, classification ---
$f:\R^n \rightarrow \{1,\ldots,k\}$) to obtaining a different representation for the data that
has beneficial properties for further processing but preserves as much information as possible
(e.g.\ PCA for compression)~\citep{goodfellow_deep_2016}.
Note that the learning itself is not the task but merely the process of improving on performing the
task~\citep{goodfellow_deep_2016}.
One of the most well known \ac{ML} algorithms is Linear Regression.
In the following the algorithm is used as an example for explaining \ac{ML} principles.
As the name implies, Linear Regression is used to predict a value $\hat{y}\in\R$ given the input vector
$\x\in\R^n$ which is made up of the features $x_i$.
The goal is to approximate the ground truth $y$.
Linear is derived from the underlying model shown in Equation~\ref{eq:linReg}:
\begin{equation}\label{eq:linReg}
    f(\x;\w,b) = \w^{T} \cdot \x + b = \sum_{i=1}^{n} w_i x_i + b = \hat{y}
\end{equation}
The scalar product of the weights $\w\in\R^n$ and \x\ is added to the bias term $b\in\R$.
Both $\w,b$ are parameters that are learned by the model in order to optimize the
approximation~\citep{goodfellow_deep_2016}.
% FIXME: here figure with linear regression

The performance of a model measures how well the task can be completed.
Depending on the task of the \ac{MLS}, different quantitative measures are used.
The metric Mean Squared Error (see Equation~\ref{eq:mse}) can be used for Linear Regression.
\begin{equation}\label{eq:mse}
    MSE =\frac{1}{m}\norm{{(\hat{\textbf{y}} - \textbf{y})}}^2
        =\frac{1}{m}\sum_{i=1}^m {((\w^T \x^{(i)} + b) - \yti)}^2
\end{equation}
Here $m$ denotes the number of examples $\xti$ with the associated targets $\yti$, used to calculate
the error~\citep{geron_hands-machine_2017,goodfellow_deep_2016}.
The goal is to minimize the generalization error which measures the expected performance on
previously unseen input~\citep{geron_hands-machine_2017}.
For this the test set is used, once the model has been trained.
The test set is a part of the available data~\citep{geron_hands-machine_2017, goodfellow_deep_2016}.
The generalization error can be divided into three components.
The bias error arises from simplifying assumptions for the model, the variance error measures the
variation in the model outcome depending on the data used for training.
Both these errors are influenced by the model's capacity which is why the relationship between them
is call the Bias/Variance tradeoff.
Lastly the irreducible error stems from not having measured all data as well as the variation
in real data and cannot be
reduced~\citep{ashmore_assuring_2021, james_introduction_2013,geron_hands-machine_2017}.

The experience part of \ac{ML} depicts the process where the algorithm is `experiencing' the training
dataset $\Xt$ and is learning important properties of the dataset.
In general, there are two paradigms for training: supervised and
unsupervised~\citep{goodfellow_deep_2016}.
Linear Regression is an example for supervised learning, as the model is using the ground truth value
to learn approximating $\yti$\ for the associated input
$\xti$~\citep{alzubi_machine_2018,goodfellow_deep_2016}.
For unsupervised learning on the other hand the algorithm is not directed to predict a target
value but to learn properties about the data and to leverage them for representation tasks
like compressing or denoising the data~\citep{goodfellow_deep_2016,geron_hands-machine_2017}.
In most cases training can be described as an optimization problem, i.e.\ as minimizing a
function --- the so called objective or loss function~\citep{goodfellow_deep_2016}.
The MSE introduced earlier can be used for Linear Regression (see Equation~\ref{eq:mseOpt}).
This objective function has properties which make it suitable for models which have linear
output~\citep{goodfellow_deep_2016}. % FIXME: define as L
\begin{equation}\label{eq:mseOpt}
    \min_{\w,b} MSE(\w,b)
\end{equation}
Note that for minimization the MSE is a function of $\w,b$ and not of $\x$, in terms of
predicting a value the MSE is a function of $\x$ parametrized by $\w,b$ (see Equation~\ref{eq:mseOpt}).
In Equation~\ref{eq:linReg} \w,$b$ are parameters that have to be learned in order to minimize
the generalization error~\citep{james_introduction_2013,geron_hands-machine_2017}.
For other tasks such as binary classification, the metric (e.g. \fone) and the
objective function (binary cross entropy loss) are different~\citep{geron_hands-machine_2017,
ho_real-world-weight_2020}.
% FIXME: simple gradient descent figure / learning process graphic
For optimization the \ac{GD} algorithm is prevalent, especially in the subfield of \ac{DL}.
As the name suggests, the gradient is used to iteratively update the parameters $\w,b$ to arrive
at a minimum of the objective function (see Equation~\ref{eq:gradDescW}
and~\ref{eq:gradDescb})~\citep{geron_hands-machine_2017}.
\begin{equation}\label{eq:gradDescW}
    \w \leftarrow \w - \epsilon \cdot \nabla_{\w} MSE(\w,b) = \w-\frac{2\epsilon}{m}\Xt^T (\Xt\w+b-\y)
\end{equation}
\begin{equation}\label{eq:gradDescb}
    b \leftarrow b - \epsilon \cdot \frac{\delta}{\delta b} MSE(\w,b) = b-\frac{2\epsilon}{m}(\Xt\w+b-\y)
\end{equation}
The learning rate constant $\epsilon$ can be adjusted to speed up or slow down the `steps' which
can have different effects on the convergence~\citep{goodfellow_deep_2016}.
There are more sophisticated variations of the \ac{GD} algorithm which are more suited for practical
application (e.g. RMSProp, Adam)~\citep{geron_hands-machine_2017}.
Note that the process minimizes the test error with the test set $\Xt$.
The effect on the generalization error depends on model capacity which is the space of functions
the model enables~\citep{goodfellow_deep_2016}.
Linear Regression has the capacity to fit data with a linear relationship between features and
ground truth.
If the underlying relationship is more complicated, the model can only underfit the data (model
bias)~\citep{goodfellow_deep_2016}.
Polynomial Regression has more capacity for example.
Say the real relationship between features and ground truth now actually is linear;
the Polynomial Regression model can overfit for statistical outliers in the test set which is why
in this case the model with the lower capacity can achieve a lower generalization
error~\citep{geron_hands-machine_2017}.
Therefore, it is important to improve the bias/variance tradeoff.
Aside from model selection, there are different techniques use for this (e.g.
Regularization)~\citep{goodfellow_deep_2016}.
% FIXME: figure for underfitting/overfitting -> LinRegr - Under, PolRegr - Over / Fig 5.3 goodfellow

\section{Deep Learning}
In \ac{DL}, \acp{DNN} are leveraged to automatically learn new representations of data through
multiple layers of abstraction.
This makes \acp{DNN} powerful function approximators~\citep{goodfellow_deep_2016}.
In this section the basics of \acp{NN} are explained and popular basic architectures thereof are
introduced.

% FIXME: small figure of simple MLP
The most basic \ac{NN} is called a feedforward \ac{NN} or \ac{MLP} where the information only
flows in one direction (in contrast to \acp{RNN} or Transformers)~\citep{goodfellow_deep_2016}.
The network is made up of artificial neurons.
These neurons are arranged as a directed acyclic graph with multiple so
called layers~\citep{goodfellow_deep_2016}.
The first layer which receives the input features $\x$ is called the input layer, the last layer
which outputs the final estimation of $\hat{y}$ or $\hat{\y}$ is called the output layer, all layers in between
are called the hidden layers~\citep{shrestha_review_2019}.
The structure with which the \ac{NN} is build in terms of how many layers, how many neurons in each
layer and how they are connected, is called architecture~\citep{goodfellow_deep_2016}.
The number of layers $d$ is refered to as depths, whereas the dimensionality of those layers is
called the width $w$~\citep{goodfellow_deep_2016}.
% FIXME: figure with MLP - layers and connections, input, hidden, output
A neuron, the basic building block of \acp{NN}, receives input from neurons in the previous layer
and calculates a single value which is propagated to neurons in the following
layer~\citep{shrestha_review_2019}.
The value is calculated by feeding the received information into a Linear Regression model (see
Equation~\ref{eq:linReg}).
The resulting value is fed into an activation function $g$ which introduces nonlinearity, to allow
more complicated transformations of information and representation~\citep{goodfellow_deep_2016}.
\begin{equation}\label{eq:neuron}
    f(\x;\T) = g(\T\x)=\z
\end{equation}
Here $f$ denotes the function which is performed by a layer of neurons (linear regression + activation).
The parameters of the individual neurons are grouped together to $\T$ ($\T_:,n$ equals 1 for the
bias term).
Popular activation functions include ReLU, tanh, sigmoid~\citep{shrestha_review_2019}.
\begin{equation}\label{eq:relu}
    ReLU(x)=\max(0,x)
\end{equation}
\begin{equation}\label{eq:tanh}
    \tanh(x)=\frac{e^{2x}-1}{e^{2x}+1}
\end{equation}
\begin{equation}\label{eq:sigmoid}
    \sigma(x)=\frac{1}{1+e^{-x}}
\end{equation}
% FIXME: figure with functions layed over each other
Note that for e.g.\ regression, the output layer can omit the activation
function~\citep{goodfellow_deep_2016}.
% FIXME: change for one neuron (currently layer)
The calculation of the prediction is basically a concatenation of the functions defined by the
layers and their neurons, the process of which is called forwardpropagation~\citep{goodfellow_deep_2016}.
\begin{equation}\label{eq:NNconcat}
    \hat{y}=f(\ldots f(f(\x;\T^{(1)});\T^{(2)})\ldots;\T^{(d)})
\end{equation}
$\T^{(i)}$ in Equation~\ref{eq:NNconcat} stands for the parameters in layer i with $\T^{(i)}_{j,:}$
being the parameters the $j$-th neuron in that layer~\citep{goodfellow_deep_2016}.
The forwardpropagation can also be described by a computational graph~\citep{goodfellow_deep_2016}.
% FIXME: computational graph figure

The term \ac{DNN} comes from adding many hidden layers to the \ac{NN}~\citep{shrestha_review_2019}.
This allows for a more complicated function and better developed features or representations that
are extracted from the input feature vector $\x$~\citep{oyedotun_deep_2015}.
The \ac{DNN} can be trained as a whole, thus making feature engineering redundant in contrast to
normal \ac{ML} algorithms~\citep{arpteg_software_2018}.
The training algorithm is called backpropagation.
It makes use of the chain rule of calculus (see Equation~\ref{eq:chainCalc}) which allows the
algorithm to propagate the training error that is calculated through the objective function in
conjunction with the output of forwardpropagation~\citep{goodfellow_deep_2016}.
For this the chain rule of calculus (see Equation~\ref{eq:chainCalc}) can be used to modularly,
recursively used to propagate the loss backwards to use \ac{GD}.
\begin{equation}\label{eq:chainCalc}
    \frac{dz}{dx}=\frac{dz}{dy}\frac{dy}{dx}
\end{equation}
The upstream gradient that is coming from neurons in the next layer is multiplied with the
jacobian matrix of the current neuron to produce the downstream gradient that is then used by
the preceding layer~\citep{boue_deep_2018,goodfellow_deep_2016}.
\begin{equation}\label{eq:backPropNeuronW}
    \frac{\delta f}{\delta\w} = \frac{\delta f}{\delta\z} \frac{\delta\z}{\delta\w}
\end{equation}
\begin{equation}\label{eq:backPropNeuronX}
    \frac{\delta f}{\delta\x} = \frac{\delta f}{\delta\z}\frac{\delta\z}{\delta\x}
\end{equation}
The result of Equation~\ref{eq:backPropNeuronW} is used to update the neuron's weights \w\ while
the result of Equation~\ref{eq:backPropNeuronX} is used for further propagation~\citep{boue_deep_2018}.
This calculation is performed until the first layer of the computational graph is
reached~\citep{goodfellow_deep_2016}.
Note that the algorithm can be performed with tensors of arbitrary
dimensionality~\citep{goodfellow_deep_2016}.

\section{Scene Text Spotting}
\ac{OCR} is the concept of extracting typed, handwritten or printed text
from an image~\citep{zhao_improving_2020}.
Achieving satisfactory performance of \ac{OCR} systems in natural scenes is still
challenging~\citep{zhao_improving_2020, chen_text_2021}.
Such scenes entail natural scenes captured by a camera~\citep{chen_text_2021, baek_what_2019}.
The difficulties arise from diviersity and variability of text, complexity and interference from
backgrounds and imperfect imaging conditions.
In these conditions \ac{OCR} is known as \ac{STS}~\citep{long_scene_2021}.

Before the advent of \ac{DL}, researchers in the field had to hand-craft features~\citep{long_scene_2021}.
\ac{DL} automates the feature generation process with its representation and learning
capabilities~\citep{long_scene_2021,goodfellow_deep_2016}.
Because of this, \ac{DL} methods are the prefered tools for performing \ac{STS}~\citep{long_scene_2021}.

\ac{OCR} and \ac{STS} are often divided into two subcategories (Scene) Text Detection and (Scene)
Text Recognition~\citep{zhao_improving_2020, long_scene_2021,chen_text_2021}.
For \ac{STD} the task is to localize text instances in the image, whereas the \ac{STR} task
is to recognize/categorize text from already cropped images~\citep{chen_text_2021}.
Note that a system which performs both \ac{STR} and \ac{STD} in one continuous pipeline are called
end-to-end approaches~\citep{chen_text_2021}.

To assess the performance of the developed approaches for \ac{STS}, specific metrics which fit the
task have to be used.
% FIXME: STD regression, STR/STS classification
\ac{STD} can loosely be categorized as a regression task. % FIXME: source
\ac{STS} and \ac{STR} on the other hand resembles classification.
Therefore, evaluation the popular protocols Precision, Recall and the \fone\ are used for
comparison among approaches.
\begin{equation}\label{eq:P}
    \text{Precision}=\frac{\text{True Positive}}{\text{True Positive + False Positive}}
\end{equation}
\begin{equation}\label{eq:R}
    \text{Recall}=\frac{\text{True Positive}}{\text{True Positive + False Negative}}
\end{equation}
\begin{equation}\label{eq:f1}
    F_1\text{-Score}=\frac{2\cdot \text{Precision}\cdot \text{Recall}}{\text{Precision}+\text{Recall}}
\end{equation}


Scene Text Detection and Recognition~\citep{long_scene_2021}
Evaluation protocols: match prediction to ground truth
\begin{itemize}
    \item general
        \begin{itemize}
            \item Precision P:\ proportion of predicted text instances that can be matched to ground
                truth labels
            \item Recall R:\ proportion of ground truth labels that have correspondents in predicted
                list
            \item F1-Score: $F_1=\frac{2PR}{P+R}$
        \end{itemize}
        $S_{GT}$: area of ground truth bounding box, $S_P$: area of oredicted bounding box,
        $S_I$: area of intersection of predicted and ground truth bounding box, $S_U$:: area of union
        \begin{itemize}
            \item PASCAL Eval: IOU based --- P $\frac{S_I}{S_P}$ and R $\frac{S_I}{S_{GT}}$ larger
                than threshhold to match
            \item DetEval: overlap based --- intersection over union value $\frac{S_I}{S_U}$
                larger than threshhold to match
            \item match score may be different from two protocols in slight variations
        \end{itemize}
    \item Text Recognition and End-to-End System
        \begin{itemize}
            \item % FIXME: go on here
        \end{itemize}
\end{itemize}

Text Recognition in the Wild: A Survey~\citep{chen_text_2021}
Normalized Edit Distance (NED) to measure mismatching between prediction and ground truth
\[NED = \frac{1}{N}\sum_{i=1}^N \frac{D(s_i,\hat{s}_i)}{\max(l_i,\hat{l_i})}\]
with $D(.)$ for Levenshtein distance, s for predicted text, l for text length, N for total number of lines

recognition protocols (W --- total number of words, $W_r$ number of correctly recognized words)
\begin{itemize}
    \item Word Recognition Accuracy: $\frac{W_r}{W}$
    \item Word Error Rate: $1 - \frac{W_r}{W}$
\end{itemize}
end-to-end protocols
\begin{itemize}
    \item precision, recall and f-score based on NED
    \item average NED, i.e., AED --- NED for all images summed and then divided bz number
\end{itemize}

Introduce Benchmark Datasets
