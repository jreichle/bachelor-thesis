\chapter{Problem analysis}\label{ch:problem}
This chapter entails an analysis of the problem which is the research question's foundation.
As the quality of requirements ultimately determines the quality of the literature review this
chapter is crucial.
The basic problem can be described as extracting textual data from images with the following
features; The relevant text information is `framed' by the label and is structured in key-value
pairs like `Serial-No. \quad 1234567', the text can have different spacing inside the label.

Make Pipeline the problem?

Requirements
\begin{itemize}
    \item problem desc / functional
        \begin{itemize}
            \item extract printed textual data from image
            \item extract with same spacing || simply extract and keep semantical spacing
            \item pattern match semantic value of text --- serial number, \ldots
            \item where to put extracted text? html, pdf?
            \item accuracy/reliability: which metric to use (considered functional for
                ML~\cite{vogelsang_requirements_2019})
        \end{itemize}
    \item non-functional: restricts degree of freedom for solution for functional requirements
        \begin{itemize}
            \item efficiency $\rightarrow$ because of mobile phone
            \item portability $\rightarrow$ kind of mobile phone, also usable on e.g. MacBook
            \item discuss: conditions for data preparation, definitions of outlieres,
                derived data
            \item different mobile phone cameras $\rightarrow$ resolutions, \ldots
            \item mobile phone computational capabilities
                $\rightarrow$ performance, GPU/ANE
            \item no internet access
            \item image properties
                \begin{itemize}
                    \item only printed text
                    \item different fonts, font sizes
                    \item different spacings
                    \item image quality threshhold: fuzzy, blurry, pixels
                    \item rotation
                \end{itemize}
            \item complexity of training
            \item preprocessing needs
        \end{itemize}
    \item Data Requirements $\rightarrow$ training, tuning, testing: `Based on our interviews,
        we would add “training data needs specified and validated requirements like
        code”'~\cite{vogelsang_requirements_2019}
        \begin{itemize}
            \item Quantity: constraints on amount of data necessary
            \item Quality: better quality $\rightarrow$ better application $\rightarrow$ clean and
                augment data is important\\
                most important quality dimensions: completeness, consistency, correctness
        \end{itemize}
\end{itemize}

pipeline definition or just recommendation for model?


delimination here: The focus of this \the\arbeit\ is limited to \ldots

not executed but analzed for model in regards to feasability
\begin{itemize}
    \item implementation
    \item training
    \item deployment
    \item maintaining
\end{itemize}


Def Requirements~\cite{zowghi_requirements_2014}
\begin{itemize}
    \item functional: specify functions that a system or system component must deliver to
        users~\cite{noauthor_ieee_1998}
    \item non-functional: other requirements that play important role in shaping target system,
        defining the development process and managing the development project~\cite{kotonya_requirements_1998, chung_non-functional_2009}
\end{itemize}

challenges from DL perspective~\cite{arpteg_software_2018}
\begin{itemize}
    \item Development
        \begin{itemize}
            \item `It is challenging to provide a sample that includes all the edge cases that
                may exist in the full dataset. Also, as the external world is dynamic and changes
                over time, new edge cases will continue to appear later in time.'
            \item `A major challenge in developing DL systems is the difficulties in estimating
                the results before a system has been trained and tested.'
            \item reproducible results dependent on components like hardware, platform, \ldots
        \end{itemize}
    \item Production
    \item Organizational
\end{itemize}

Requirements Engineering for Machine Learning~\cite{vogelsang_requirements_2019}
`In addition, a recent survey suggests that Requirements Engineering (RE) is the most difficult
activity for the development of ML-based systems [2].'

\section{Functional Requirements}

\section{Non-Functional Requirements}

\section{Tradeoff}
Note: tradeoff between accuracy and computational cost $\rightarrow$ mobile phone dilemma

When determining whether automisation is an improvement four aspects have to be examined.
These are time, costs, quality and flexibility.
The aspects build a quadrangle that is based on the optimizing trade-off between the
factors~\cite{dumas_fundamentals_2013}.

Without software supporting the task of reading the name of the picture and typing it into
the system, can take long seconds, whereas a trained Deep Learning model could complete the task
in a mere instant.
Therefor automisation via Deep Learning should improve the efficiency of the process when compared to
manually reading and typing the information off the image.

Training costs for a Deep Learning model are very high due to the computing intensive
backpropagation algorithm that tunes the network to the data.
But the usage cost is low.
For manual labor the opposite is the case as training a person to type in a label is done quickly
and labor costs are high in comparison to the expenses for running the model.

Both Deep Learning models and human labor are not 100\% accurate.
The question is whether the model can be as accurate or even better than its human counterpart.
This is especially interesting when it is applied in the real world where it might have to do good
in subpar situations.
An example is bad image quality.

Flexibility is concerned with how well a process can adjust to changing requirements.
A set of new equipment names that have to be included can pose a problem to a Deep Learning model
because it is not trained for the new data.
A human on the other hand should not have any problems in this regard.

The main concern for the solution's efficacy is whether it is accurate enough.
Therefor this work focuses on this aspect in particular.
