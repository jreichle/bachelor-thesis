\chapter{Discussion}\label{ch:discussion}
\section{Analysis}
Go down hierarchy and compare most important advances
\begin{itemize}
    \item Compare: two step, two stage, parallel
    \item Compare: innovations for specific steps/stages
\end{itemize}

\begin{table}[ht]
    \centering\scriptsize
    \begin{tabular}{p{.1\textwidth}p{.15\textwidth}p{.1\textwidth}p{.55\textwidth}}
        Task & \multicolumn{2}{c}{Approach} & Shortcommings \\
        \toprule
        STD & Seg free & & Curved text~\citep{long_scene_2021} \\
            & & & Higher aspect ratios~\citep{long_scene_2021,shi_detecting_2017}\\
            & & & Text orientation~\citep{shi_detecting_2017} \\
            & & 1-stage & \\
            & & 2-stage & \\
            & Seg based & & \\
            & & Pixel-level & \\
            & & Component-level & \\
            & & Character-level & \\
        \midrule
        STR & Seg based & & \\
            & Seg free & & \\
            & & CTC based &  \\
            & & Attention based & \\
        \midrule
        E2E & 2-step & & \\
            & Parallel & & \\
        \bottomrule
    \end{tabular}
    \caption{Tasks, method categories and their shortcomings\label{tb:steps-properties}}
\end{table}

For comparison: which Benchmark Dataset fits the problem the best?
\begin{itemize}
    \item~\cite{liao_mask_2020}:
        \begin{itemize}
            \item Rotated ICDAR 2013 (changed normal icdar): rotation robustness
            \item Total-Text: shape ropustness
            \item MSRA-TD500: aspect ratio ropustness
        \end{itemize}
    \item~\cite{yang_learning_2021}:commonly used for oriented text: ICDAR2015, ICDAR2017 MLT,
        MSRA-TD500
\end{itemize}

Detection
\begin{itemize}
    \item~\cite{ferrari_textsnake_2018}: many methods have strong assumption that text instances are
        in linear shape and therefore adopted simple representations (rectangles --- axis aligned
        or rotated, quadrangles) $\rightarrow$ problem with irregular and curved text
    \item~\cite{ferrari_textsnake_2018}: some models are specifically designed for arbitrary shapes
    \item~\cite{shi_detecting_2017}: modular approach instead of whole \acp{BB}
        $\rightarrow$ good with long aspect ratio and orientation because of flexibility
\end{itemize}

Recognition
\begin{itemize}
    \item Ability to cope with 2d text:
        CTC has problems,
        Attention/Encoder-Decoder based can be extended to work
    \item CTC prone to overfitting
    \item Attention has problems with long sequences
\end{itemize}

\section{Reflection}
Threats to validity!
\begin{itemize}
    \item~\cite{arpteg_software_2018}: different papers have different components
        $\rightarrow$ Hardware, Platform, Source Code, Configuration
        $\rightarrow$ studies can't really be compared
    \item~\cite{arpteg_software_2018}: `A major challenge in developing DL systems is the
        difficulties in estimating the results before a system has been trained and tested.'
    \item~\cite{long_scene_2021}: different interpretations of metrics (matching for \ac{STD},
        word/char for \ac{STR})
    \item~\cite{siebert_construction_2021,nakamichi_requirements-driven_2020}: all entities of
        \ac{MLS} should be inspected when developing a solution
    \item~\cite{baek_what_2019}: different papers use different evaluation and testing environments
    \item~\cite{baek_what_2019}: different papers use different subsets of the same dataset
        $\rightarrow$ discrepancies in performance
    \item~\cite{long_unrealtext_2020}: half of the widely adopted benchmark datasets have imperfect
        annotations $\rightarrow$ ignoring case-sensitivities and punctuations, and provide new
        annotations for those datasets
    \item~\cite{chen_text_2021}: inconsistency of datasets, priors and testing environments make
        comparison difficult
\end{itemize}

\section{Outlook}

\begin{itemize}
    \item~\cite{watanabe_preliminary_2019}:next steps to practically solve problem
        $\rightarrow$  Data Collection, Data Cleaning, Data Labeling, Model Training,
        Model Evaluation, Model Deployment, Model Monitoring
    \item~\cite{zhao_improving_2020}: Use Neural Architecture Search to automatically find right
        feature extractor
    \item~\cite{siebert_construction_2021,nakamichi_requirements-driven_2020}: build system around
        model $\rightarrow$ e.g.\ supervision mechanism
    \item~\cite{shi_icdar2017_2017,he_icpr2018_2018}: adjust field to better metrics for evaluation
    \item~\cite{long_scene_2021}: general trend to move towards simpler,shorter pipeline
\end{itemize}
